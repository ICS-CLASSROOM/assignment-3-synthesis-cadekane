{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Assignment Overview: Working with Patient Records and Encounter Notes\n",
    "\n",
    "In this final assignment, we’ll focus on patient records related to COVID-19 encounters. Our task is to analyze, process, and transform the data while applying the concepts we’ve covered throughout this course. Here's a detailed breakdown of the assignment:\n",
    "\n",
    "What Are Encounter Notes?\n",
    "An encounter note is a record that captures details about a patient’s visit with a doctor. It includes both structured and semi-structured information that is crucial for understanding the context of the visit. Here’s what an encounter note typically looks like:\n",
    "\n",
    "\n",
    "The encounter contains:\n",
    "\n",
    "* General encounter information: \n",
    "\n",
    "  * When the encounter took place: Date and time of the visit.\n",
    "  * Demographics: Patient’s age, gender, and unique medical record identifier.\n",
    "  * Encounter details: The reason for the visit, diagnosis, and any associated costs.\n",
    "\n",
    "\n",
    "Semi-Structured Notes:\n",
    "\n",
    "These notes mirror how doctors organize their thoughts and observations during an encounter. They generally follow a SOAP format:\n",
    "\n",
    "* **Subjective**: The patient’s subjective description of their symptoms, feelings, and medical concerns.\n",
    "* **Objective**: The doctor’s objective findings, including test results, measurements, or physical examination outcomes.\n",
    "* **Assessment**: The doctor’s evaluation or diagnosis based on subjective and objective information.\n",
    "* **Plan**: The proposed treatment plan, including medications, follow-ups, or other interventions.\n",
    "\n",
    "While some encounter notes might include additional details, the majority conform to this semi-structured format, making them ideal for analysis and transformation.\n",
    "\n",
    "* Goals for the Assignment\n",
    "\n",
    "## 1. Transforming Encounter Notes:\n",
    "\n",
    "Using an LLM to convert semi-structured encounter notes into a JSON format that organizes the information into structured fields. The JSON will include details such as demographics, encounter specifics, and the SOAP components of the note. Subsequently, you will need to transform the JSON data into a Parquet file, which is not only suitable for analysis in Spark but also ideal for storage later.\n",
    "Here we will use the ML classificaition to assing the objective and assessment semi-structured fields into standardized, structured fields. The medical taxonomy for this task will be the one provided by the CDC, which defines standard codes for diagnoses, symptoms, procedures, and treatments. This step ensures the structured data aligns with domain-wide medical standards, making it interoperable and ready for deeper analysis.\n",
    "\n",
    "The JSON format should capture the hierachies described in the structure below. \n",
    "\n",
    "### From Explanation:\n",
    "- There is a code related to each symptom – this will help us turn the Subjective description into structured data.\n",
    "- We want everything to have a code associated with it. We will use an LLM. Ask it to give us some structured data. \n",
    "- **We have to generate a plan of what the structure will look like.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Basic Analytics and Visualizations:\n",
    "Using Apache Spark, perform comprehensive data analysis on the encounter data and create visualizations that reveal meaningful patterns. Your analysis must include:\n",
    "- COVID-19 Case Demographics: Case breakdown by age ranges ([0-5], [6-10], [11-17], [18-30], [31-50], [51-70], [71+])\n",
    "- Cumulative case count of Covid between the earliest case observed in the dataset and last case observed\n",
    "\n",
    "- Symptoms for all COVID-19 patients versus patients that admitted into the intensive care unit due to COVID.\n",
    "- *This will use encounters_assignment_1.csv and encounters_types_assignment_1.csv: Intensive care unit has a specific encounter code; then we can*\n",
    "\n",
    "- Rank medications by frequency of prescription\n",
    "- Analyze medication patterns across different demographic groups (e.g., top 3 per age group)\n",
    "- Identify and plot co-morbidity information from the patient records (e.g., hypertension, obesity, prediabetes, etc.) provided in the dataset. \n",
    "\n",
    "- An independent group analysis: You need to develop and execute **THREE original analyses** that provide meaningful insights about COVID-19 patterns in this dataset. For each analysis:\n",
    "  - Clearly state your analytical question/hypothesis\n",
    "  - Justify why this analysis is valuable\n",
    "  - Show your Spark code and methodology\n",
    "  - Present results with appropriate visualizations\n",
    "  \n",
    "The analyses should be actionable, informative, and helpful with regard to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan for what the structure should look like after putting it into an LLM:\n",
    "- We should turn this template into a JSON file.\n",
    "- We use a Pydantic Model with structured output and an encounter. Each of these is a Pydantic Class.\n",
    "- We also want the data to contain codes for things like symptoms or encounter types instead of the English descriptions. *How can we do this when the codes are in the csv files? How can we provide the codes?*\n",
    "- We should provide the codes as part of the prompt. But we need two prompts; for example:\n",
    "1. LLM finds the medication names in the file. (more generally, extract stuff NOT dependent on your database)\n",
    "- Use FAISS similarity, find the 10 most similar items for your description by their embeddings, not text, then get those entries in your \"database\" csv, and include them in your context. This is Retrieval Augmented Generation. \n",
    "2. Submit your second prompt with the code and description in the context (it is a SUBSET of your entire database, relevant for your specific file), so you're saving tokens, and then it can provide that as part of your Medications object with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydantic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMedication\u001b[39;00m(BaseModel):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic'"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Medication(BaseModel):\n",
    "    code: str \n",
    "    description: str\n",
    "\n",
    "class Address(BaseModel):\n",
    "    city: str\n",
    "    state: str\n",
    "\n",
    "class Demographics(BaseModel):\n",
    "    name: str \n",
    "    date_of_birth: str \n",
    "    age: str\n",
    "    gender: str\n",
    "    address: Address\n",
    "    insurance: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Use prompt prefix with the Pydantic output parser instructions with the input variable being the encounter text file\n",
    "prompt =\n",
    "\n",
    "api_key = \"\"\n",
    "model = OpenAI()\n",
    "chain = LLMChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncounterType:\n",
    "    code\n",
    "    description\n",
    "\n",
    "Encounter:\n",
    "    date\n",
    "    time\n",
    "    type: EncounterType\n",
    "    provider_id\n",
    "    facility_id\n",
    "\n",
    "Address:\n",
    "    city\n",
    "    state\n",
    "\n",
    "Demographics:\n",
    "    name\n",
    "    date_of_birth\n",
    "    age\n",
    "    gender\n",
    "    address: Address\n",
    "    insurance\n",
    "\n",
    "Condition:\n",
    "    code\n",
    "    description\n",
    "\n",
    "Medication:\n",
    "    code\n",
    "    description\n",
    "\n",
    "Immunization:\n",
    "    code\n",
    "    description\n",
    "    date: date\n",
    "\n",
    "VitalMeasurement:\n",
    "    code\n",
    "    value: float\n",
    "    unit\n",
    "\n",
    "BloodPressure:\n",
    "    systolic: VitalMeasurement\n",
    "    diastolic: VitalMeasurement\n",
    "\n",
    "CurrentVitals:\n",
    "    temperature: VitalMeasurement\n",
    "    heart_rate: VitalMeasurement\n",
    "    blood_pressure: BloodPressure\n",
    "    respiratory_rate: VitalMeasurement\n",
    "    oxygen_saturation: VitalMeasurement\n",
    "    weight: VitalMeasurement\n",
    "\n",
    "BaselineVitals:\n",
    "    date: date\n",
    "    height: VitalMeasurement\n",
    "    weight: VitalMeasurement\n",
    "    bmi: VitalMeasurement\n",
    "    bmi_percentile: VitalMeasurement\n",
    "\n",
    "Vitals:\n",
    "    current: CurrentVitals\n",
    "    baseline: BaselineVitals\n",
    "\n",
    "RespiratoryTest:\n",
    "    code\n",
    "    result\n",
    "\n",
    "RespiratoryPanel:\n",
    "    influenza_a: RespiratoryTest\n",
    "    influenza_b: RespiratoryTest\n",
    "    rsv: RespiratoryTest\n",
    "    parainfluenza_1: RespiratoryTest\n",
    "    parainfluenza_2: RespiratoryTest\n",
    "    parainfluenza_3: RespiratoryTest\n",
    "    rhinovirus: RespiratoryTest\n",
    "    metapneumovirus: RespiratoryTest\n",
    "    adenovirus: RespiratoryTest\n",
    "\n",
    "Covid19Test:\n",
    "    code\n",
    "    description\n",
    "    result\n",
    "\n",
    "Laboratory:\n",
    "    covid19: Covid19Test\n",
    "    respiratory_panel: RespiratoryPanel\n",
    "\n",
    "Procedure:\n",
    "    code\n",
    "    description\n",
    "    date: date\n",
    "    reasonCode\n",
    "    reasonDescription\n",
    "\n",
    "CarePlan:\n",
    "    code\n",
    "    description\n",
    "    start: date\n",
    "    stop: date\n",
    "    reasonCode\n",
    "    reasonDescription\n",
    "\n",
    "PatientRecord:\n",
    "    encounter: Encounter\n",
    "    demographics: Demographics\n",
    "    conditions: List[Condition]\n",
    "    medications: List[Medication]\n",
    "    immunizations: List[Immunization]\n",
    "    vitals: Vitals\n",
    "    laboratory: Laboratory\n",
    "    procedures: List[Procedure]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of what we want ChatGPT to output\n",
    "{\n",
    "    \"encounter\": {\n",
    "        \"date\": \n",
    "        \"time\":\n",
    "        \"provider_id\":\n",
    "        \"encounter_id\":\n",
    "    },\n",
    "    …\n",
    "    \"medications\": [\n",
    "        {},\n",
    "        {}\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Assignment 2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "ICS235",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
